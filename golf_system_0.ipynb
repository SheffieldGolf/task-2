{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# use in both train and dev.\n",
    "vclaims = pd.read_csv('data/verified_claims.docs.tsv', sep='\\t').rename(columns = {\"Unnamed: 0\": \"id\"})\n",
    "# training dataset.\n",
    "tweets = pd.read_csv('data/train/tweets.queries.tsv', sep='\\t').rename(columns = {\"Unnamed: 0\": \"id\"})\n",
    "tweet_vclaim = pd.read_csv('data/train/tweet-vclaim-pairs.qrels', sep='\\t', header=None, names=['tweet_id', '0', 'vclaim_id', 'relevance'])\n",
    "# development dataset.\n",
    "dev_tweets = pd.read_csv('data/dev/tweets.queries.tsv', sep='\\t').rename(columns = {\"Unnamed: 0\": \"id\"})\n",
    "dev_tweet_vclaim = pd.read_csv('data/dev/tweet-vclaim-pairs.qrels', sep='\\t', header=None, names=['tweet_id', '0', 'vclaim_id', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vclaim</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>122 detainees released from confinement at Gua...</td>\n",
       "      <td>Did 122 Prisoners Released from Guantanamo by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A \"Trump and Obama by the Numbers\" meme recoun...</td>\n",
       "      <td>Does This Meme Accurately Show ‘Trump and Obam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A \"large-scale killing\" of white farmers is ta...</td>\n",
       "      <td>Is a ‘Large-Scale Killing’ of White Farmers Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A \"law to separate families\" was enacted prior...</td>\n",
       "      <td>Was the ‘Law to Separate Families’ Passed in 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A \"newly uncovered\" photograph reveals Alexand...</td>\n",
       "      <td>Does an Image Show Ocasio-Cortez Fake-Crying a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>A 13 percent increase in police-recorded crime...</td>\n",
       "      <td>Is an Increase in Recorded Crime in England an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>A 13-year-old girl was beheaded by an \"illegal...</td>\n",
       "      <td>Police: 13-Year-Old Girl Was Beheaded After Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A Broward County employee witnessed elections ...</td>\n",
       "      <td>Did a Broward County Employee Witness Election...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A California couple gave their newborn child a...</td>\n",
       "      <td>Did a California Newborn Become the First Chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A Cleveland-area Fox affiliate described local...</td>\n",
       "      <td>Did a Cleveland Fox Affiliate Label a Black Mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             vclaim  \\\n",
       "0   0  122 detainees released from confinement at Gua...   \n",
       "1   1  A \"Trump and Obama by the Numbers\" meme recoun...   \n",
       "2   2  A \"large-scale killing\" of white farmers is ta...   \n",
       "3   3  A \"law to separate families\" was enacted prior...   \n",
       "4   4  A \"newly uncovered\" photograph reveals Alexand...   \n",
       "5   5  A 13 percent increase in police-recorded crime...   \n",
       "6   6  A 13-year-old girl was beheaded by an \"illegal...   \n",
       "7   7  A Broward County employee witnessed elections ...   \n",
       "8   8  A California couple gave their newborn child a...   \n",
       "9   9  A Cleveland-area Fox affiliate described local...   \n",
       "\n",
       "                                               title  \n",
       "0  Did 122 Prisoners Released from Guantanamo by ...  \n",
       "1  Does This Meme Accurately Show ‘Trump and Obam...  \n",
       "2  Is a ‘Large-Scale Killing’ of White Farmers Un...  \n",
       "3  Was the ‘Law to Separate Families’ Passed in 1...  \n",
       "4  Does an Image Show Ocasio-Cortez Fake-Crying a...  \n",
       "5  Is an Increase in Recorded Crime in England an...  \n",
       "6  Police: 13-Year-Old Girl Was Beheaded After Se...  \n",
       "7  Did a Broward County Employee Witness Election...  \n",
       "8  Did a California Newborn Become the First Chil...  \n",
       "9  Did a Cleveland Fox Affiliate Label a Black Mu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclaims[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454</td>\n",
       "      <td>Pence’s Brother sells engines to Russia. Manaf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276</td>\n",
       "      <td>Billions of dollars are sent to the State of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849</td>\n",
       "      <td>I am being proven right about massive vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>789</td>\n",
       "      <td>Little Girl To Trump: You´re A Disgrace To The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>A knife hidden in a baguette is the most Frenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>661</td>\n",
       "      <td>#MANDALAY BAY SHOOTER IDENTIFIED AS 32 YEAR OL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>870</td>\n",
       "      <td>Tweeting again: wh aide confirms the MLK bust ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>234</td>\n",
       "      <td>WATCH: President Trump met with loud boos as h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>557</td>\n",
       "      <td>“These are not hoax devices,” FBI Director Chr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67</td>\n",
       "      <td>At the opening of the South Korean baseball ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                      tweet_content\n",
       "0  454  Pence’s Brother sells engines to Russia. Manaf...\n",
       "1  276  Billions of dollars are sent to the State of C...\n",
       "2  849  I am being proven right about massive vaccinat...\n",
       "3  789  Little Girl To Trump: You´re A Disgrace To The...\n",
       "4  295  A knife hidden in a baguette is the most Frenc...\n",
       "5  661  #MANDALAY BAY SHOOTER IDENTIFIED AS 32 YEAR OL...\n",
       "6  870  Tweeting again: wh aide confirms the MLK bust ...\n",
       "7  234  WATCH: President Trump met with loud boos as h...\n",
       "8  557  “These are not hoax devices,” FBI Director Chr...\n",
       "9   67  At the opening of the South Korean baseball ch..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "804\n"
     ]
    }
   ],
   "source": [
    "dev_tweet_vclaim[:10]\n",
    "\n",
    "print(len(dev_tweet_vclaim))\n",
    "print(len(tweet_vclaim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### following data_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "url_pattern = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "username_pattern = r\"@[^\\s]+\"\n",
    "hashtag_pattern = r\"\\B#\\w\\w+\"\n",
    "token_pattern = r\"\\b[A-Za-z][A-Za-z]+\\b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of preprocessing tweet\n",
    "def preprocess_tweet(tweet, \n",
    "                     url_pattern=url_pattern, username_pattern=username_pattern, \n",
    "                     hashtag_pattern=hashtag_pattern, token_pattern=token_pattern, \n",
    "                     remove_url=True, remove_username=True, remove_hashtag=True,\n",
    "                     stopwords=stopwords, with_stopwordsrm=True, with_stemming=True):\n",
    "    # remove content after '—'\n",
    "    tweet = tweet.split('—')[0]\n",
    "    \n",
    "    # remove url\n",
    "    if remove_url == True:\n",
    "        tweet = re.sub(url_pattern, \"\", tweet)\n",
    "        \n",
    "    # remove @username \n",
    "    if remove_username == True:\n",
    "        tweet = re.sub(username_pattern, \"\", tweet)\n",
    "        \n",
    "    # remove #hashtag\n",
    "    if remove_hashtag == True:\n",
    "        tweet = re.sub(hashtag_pattern, \"\", tweet)\n",
    "    \n",
    "    # lower case \n",
    "    tweet_lower = tweet.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, tweet_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    tweet_processed = \" \".join(words)\n",
    "    \n",
    "    return tweet_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict tweets_prep: tweet_id -> tweet_content\n",
    "tweets_prep = {}\n",
    "\n",
    "for i, tid in (tweets.id).items():\n",
    "    tweets_prep[tid] = preprocess_tweet(tweets.loc[i, 'tweet_content'])\n",
    "    \n",
    "\n",
    "dev_tweets_prep = {}\n",
    "\n",
    "for i, tid in (dev_tweets.id).items():\n",
    "    dev_tweets_prep[tid] = preprocess_tweet(tweets.loc[i, 'tweet_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets_prep))\n",
    "\n",
    "print(len(dev_tweets_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of preprocessing vclaim\n",
    "def preprocess_text(text, token_pattern=token_pattern, stopwords=stopwords, \n",
    "                      with_stopwordsrm=True, with_stemming=True):\n",
    "    # lower case \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, text_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    text_processed = \" \".join(words)\n",
    "    \n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict vclaim_prep: vlciam_id -> [vlciam_content, vclaim_title]\n",
    "vclaim_prep = {}\n",
    "for i, vid in (vclaims.id).items():\n",
    "    vclaim_prep[vid] = []\n",
    "    vclaim_prep[vid].append(preprocess_text(vclaims.loc[i, 'vclaim']))\n",
    "    vclaim_prep[vid].append(preprocess_text(vclaims.loc[i, 'title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vclaim_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# need to download GoogleNews-vectors-negative300.bin. \n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc vector of training set.\n",
    "tweets_vec = {}\n",
    "\n",
    "for tid, text in tweets_prep.items():\n",
    "    train_text = [model[x] for x in text.split(' ') if x in model]\n",
    "    if len(train_text) == 0: continue\n",
    "    vector = np.array(train_text).mean(axis=0)\n",
    "    tweets_vec[tid] = vector\n",
    "    \n",
    "vclaim_vec = {}\n",
    "\n",
    "for vid, text in vclaim_prep.items():\n",
    "    train_text = [model[x] for x in text[0].split(' ') if x in model]\n",
    "    train_title = [model[x] for x in text[1].split(' ') if x in model]\n",
    "    if len(train_title) == 0 or len(train_text) == 0: continue\n",
    "    vector_text = np.array(train_text).mean(axis=0)\n",
    "    vector_title = np.array(train_title).mean(axis=0)\n",
    "    vclaim_vec[vid] = [vector_text, vector_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc vector of development dataset.\n",
    "dev_tweets_vec = {}\n",
    "\n",
    "for tid, text in dev_tweets_prep.items():\n",
    "    train_text = [model[x] for x in text.split(' ') if x in model]\n",
    "    if len(train_text) == 0: continue\n",
    "    vector = np.array(train_text).mean(axis=0)\n",
    "    dev_tweets_vec[tid] = vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "783\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# some tweets whose len is zero has been removed.\n",
    "print(len(tweets_vec))\n",
    "print(len(vclaim_vec))\n",
    "print(len(dev_tweets_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct training dataset with 4 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import random\n",
    "\n",
    "# t_v = dict(zip(list(tweet_vclaim['tweet_id']), list(tweet_vclaim['vclaim_id'])))\n",
    "# tr_X = pd.DataFrame(columns=['tid','vid','cos_c', 'Euclidean_c', 'cos_t', 'Euclidean_t', 'label'])\n",
    "\n",
    "# for tid, tweet in tweets_vec.items():\n",
    "#     if tid not in t_v: continue\n",
    "#     for vid, claim in vclaim_vec.items():\n",
    "#         x = torch.from_numpy(tweet)\n",
    "#         y1, y2 = torch.from_numpy(claim[0]), torch.from_numpy(claim[1])\n",
    "#         s1, s2 = torch.cosine_similarity(x, y1, dim=0).item(), torch.cosine_similarity(x, y2, dim=0).item()\n",
    "#         e1, e2 = torch.dist(x, y1, p=2).item(), torch.dist(x, y2, p=2).item()\n",
    "#         label = 1 if t_v[tid] == vid else 0\n",
    "#         tr_X=tr_X.append({'tid':tid, 'vid':vid, 'cos_c':s1, 'Euclidean_c':e1, 'cos_t':s2, 'Euclidean_t':e2, 'label':label},ignore_index=True)\n",
    "\n",
    "# tr_X.to_csv('tr_X_four_features.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct dev dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_t_v = dict(zip(list(dev_tweet_vclaim['tweet_id']), list(dev_tweet_vclaim['vclaim_id'])))\n",
    "# dev_X = pd.DataFrame(columns=['tid','vid','cos_c', 'Euclidean_c', 'cos_t', 'Euclidean_t', 'label'])\n",
    "\n",
    "# for tid, tweet in dev_tweets_vec.items():\n",
    "#     if tid not in dev_t_v: continue\n",
    "#     for vid, claim in vclaim_vec.items():\n",
    "#         x = torch.from_numpy(tweet)\n",
    "#         y1, y2 = torch.from_numpy(claim[0]), torch.from_numpy(claim[1])\n",
    "#         s1, s2 = torch.cosine_similarity(x, y1, dim=0).item(), torch.cosine_similarity(x, y2, dim=0).item()\n",
    "#         e1, e2 = torch.dist(x, y1, p=2).item(), torch.dist(x, y2, p=2).item()\n",
    "#         label = 1 if dev_t_v[tid] == vid else 0\n",
    "#         dev_X=dev_X.append({'tid':tid, 'vid':vid, 'cos_c':s1, 'Euclidean_c':e1, 'cos_t':s2, 'Euclidean_t':e2, 'label':label},ignore_index=True)\n",
    "        \n",
    "\n",
    "# dev_X.to_csv('dev_X_four_features.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>vid</th>\n",
       "      <th>cos_c</th>\n",
       "      <th>Euclidean_c</th>\n",
       "      <th>cos_t</th>\n",
       "      <th>Euclidean_t</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576904</td>\n",
       "      <td>1.084875</td>\n",
       "      <td>0.557494</td>\n",
       "      <td>1.147098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664090</td>\n",
       "      <td>1.109990</td>\n",
       "      <td>0.584389</td>\n",
       "      <td>1.405756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.548836</td>\n",
       "      <td>1.077028</td>\n",
       "      <td>0.502754</td>\n",
       "      <td>1.195149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>1.145715</td>\n",
       "      <td>0.613488</td>\n",
       "      <td>1.209850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.394544</td>\n",
       "      <td>1.322593</td>\n",
       "      <td>0.416105</td>\n",
       "      <td>1.289802</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1.164412</td>\n",
       "      <td>0.566732</td>\n",
       "      <td>1.284574</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>106.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.358750</td>\n",
       "      <td>1.391273</td>\n",
       "      <td>0.379697</td>\n",
       "      <td>1.472143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.415876</td>\n",
       "      <td>1.391316</td>\n",
       "      <td>0.415876</td>\n",
       "      <td>1.391316</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.468508</td>\n",
       "      <td>1.257860</td>\n",
       "      <td>0.467076</td>\n",
       "      <td>1.244315</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.600620</td>\n",
       "      <td>1.088224</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>1.262613</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tid  vid     cos_c  Euclidean_c     cos_t  Euclidean_t  label\n",
       "0  106.0  0.0  0.576904     1.084875  0.557494     1.147098    0.0\n",
       "1  106.0  1.0  0.664090     1.109990  0.584389     1.405756    0.0\n",
       "2  106.0  2.0  0.548836     1.077028  0.502754     1.195149    0.0\n",
       "3  106.0  3.0  0.516021     1.145715  0.613488     1.209850    0.0\n",
       "4  106.0  4.0  0.394544     1.322593  0.416105     1.289802    0.0\n",
       "5  106.0  5.0  0.554041     1.164412  0.566732     1.284574    0.0\n",
       "6  106.0  6.0  0.358750     1.391273  0.379697     1.472143    0.0\n",
       "7  106.0  7.0  0.415876     1.391316  0.415876     1.391316    0.0\n",
       "8  106.0  8.0  0.468508     1.257860  0.467076     1.244315    0.0\n",
       "9  106.0  9.0  0.600620     1.088224  0.539521     1.262613    0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tr_X = pd.read_csv('tr_X_four_features.csv')\n",
    "raw_dev_X = pd.read_csv('dev_X_four_features.csv')\n",
    "\n",
    "raw_tr_X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = raw_tr_X[['cos_c', 'Euclidean_c', 'cos_t', 'Euclidean_t']].values, raw_tr_X['label'].values\n",
    "\n",
    "X_dev, y_dev = raw_dev_X[['cos_c', 'Euclidean_c', 'cos_t', 'Euclidean_t']].values, raw_dev_X['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_qrel = pd.read_csv('data/dev/tweet-vclaim-pairs.qrels', names=['tweet_id', '0', 'vclaim_id', 'relevance'], sep='\\t')\n",
    "tr_qrel = pd.read_csv('data/train/tweet-vclaim-pairs.qrels', names=['tweet_id', '0', 'vclaim_id', 'relevance'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# clf = LogisticRegression(random_state=0, solver='lbfgs',class_weight={0:0.0001, 1:0.999}).fit(X_tr, y_tr)\n",
    "\n",
    "# prob_tr = clf.predict_proba(X_tr)[:, 1]\n",
    "\n",
    "# score_tr = []\n",
    "# for v in prob_tr:\n",
    "#     if v >= 0 and v < 0.2:\n",
    "#         score_tr.append(0)\n",
    "#     elif v >= 0.2 and v < 0.4:\n",
    "#         score_tr.append(1)\n",
    "#     elif v >= 0.4 and v < 0.6:\n",
    "#         score_tr.append(2)\n",
    "#     elif v >= 0.6 and v < 0.8:\n",
    "#         score_tr.append(3)\n",
    "#     else:\n",
    "#         score_tr.append(4)\n",
    "\n",
    "# raw_tr_X['prob'] = prob_tr\n",
    "# raw_tr_X['class'] = score_tr\n",
    "\n",
    "# tr_qrel_dict = dict(zip(list(tr_qrel['tweet_id']), list(tr_qrel['vclaim_id'])))\n",
    "\n",
    "# for t, v in tr_qrel_dict.items():\n",
    "#     temp = raw_tr_X[raw_tr_X['tid'] == t]\n",
    "#     index = temp[temp['vid'] == v].index\n",
    "#     raw_tr_X.loc[index, 'class'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_tr_X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',class_weight={0:0.0001, 1:0.999}).fit(X_tr, y_tr)\n",
    "\n",
    "score = (X_dev * clf.coef_).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lr_y_tr = raw_tr_X['class'].values\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# regr = LinearRegression().fit(X_tr, lr_y_tr)\n",
    "\n",
    "# score = (X_dev * regr.coef_).sum(axis=1)\n",
    "\n",
    "# print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67734033 0.04293891 0.65394966 0.04453936]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC().fit(X_tr, y_tr)\n",
    "\n",
    "score = (X_dev * svc.coef_[0]).sum(axis=1)\n",
    "\n",
    "print(svc.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>vid</th>\n",
       "      <th>cos_c</th>\n",
       "      <th>Euclidean_c</th>\n",
       "      <th>cos_t</th>\n",
       "      <th>Euclidean_t</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576904</td>\n",
       "      <td>1.084875</td>\n",
       "      <td>0.557494</td>\n",
       "      <td>1.147098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664090</td>\n",
       "      <td>1.109990</td>\n",
       "      <td>0.584389</td>\n",
       "      <td>1.405756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>454.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.548836</td>\n",
       "      <td>1.077028</td>\n",
       "      <td>0.502754</td>\n",
       "      <td>1.195149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>1.145715</td>\n",
       "      <td>0.613488</td>\n",
       "      <td>1.209850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>454.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.394544</td>\n",
       "      <td>1.322593</td>\n",
       "      <td>0.416105</td>\n",
       "      <td>1.289802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.653590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>454.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1.164412</td>\n",
       "      <td>0.566732</td>\n",
       "      <td>1.284574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>454.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.358750</td>\n",
       "      <td>1.391273</td>\n",
       "      <td>0.379697</td>\n",
       "      <td>1.472143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>454.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.415876</td>\n",
       "      <td>1.391316</td>\n",
       "      <td>0.415876</td>\n",
       "      <td>1.391316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>454.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.468508</td>\n",
       "      <td>1.257860</td>\n",
       "      <td>0.467076</td>\n",
       "      <td>1.244315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>454.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.600620</td>\n",
       "      <td>1.088224</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>1.262613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tid  vid     cos_c  Euclidean_c     cos_t  Euclidean_t  label     score\n",
       "0  454.0  0.0  0.576904     1.084875  0.557494     1.147098    0.0  0.853008\n",
       "1  454.0  1.0  0.664090     1.109990  0.584389     1.405756    0.0  0.942249\n",
       "2  454.0  2.0  0.548836     1.077028  0.502754     1.195149    0.0  0.800002\n",
       "3  454.0  3.0  0.516021     1.145715  0.613488     1.209850    0.0  0.853794\n",
       "4  454.0  4.0  0.394544     1.322593  0.416105     1.289802    0.0  0.653590\n",
       "5  454.0  5.0  0.554041     1.164412  0.566732     1.284574    0.0  0.853101\n",
       "6  454.0  6.0  0.358750     1.391273  0.379697     1.472143    0.0  0.616607\n",
       "7  454.0  7.0  0.415876     1.391316  0.415876     1.391316    0.0  0.675362\n",
       "8  454.0  8.0  0.468508     1.257860  0.467076     1.244315    0.0  0.732216\n",
       "9  454.0  9.0  0.600620     1.088224  0.539521     1.262613    0.0  0.862607"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dev_X['score'] = score\n",
    "\n",
    "raw_dev_X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP without cutoff:  0.0123198888095347\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "MAP = 0\n",
    "for i in range(len(dev_qrel)):\n",
    "    tid, vid = dev_qrel.loc[i, 'tweet_id'], dev_qrel.loc[i, 'vclaim_id']\n",
    "    temp = raw_dev_X[raw_dev_X['tid'] == tid].sort_values(by='score' , ascending=False)\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "    index = temp[temp['vid'] == vid].index\n",
    "    if len(index) == 0: continue\n",
    "    MAP += 1/(index[0]+1)\n",
    "    result = result.append(temp)\n",
    "    \n",
    "print(\"MAP without cutoff: \", MAP/len(dev_qrel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new = pd.DataFrame(columns=['tweet_id', 'Q0', 'vclaim_id', 'rank', 'score', 'tag'])\n",
    "\n",
    "tid = list(raw_dev_X.groupby(by='tid').groups.keys())\n",
    "for i in tid:\n",
    "    idx = raw_dev_X[raw_dev_X['tid'] == i]['score'].idxmax()\n",
    "    inf = raw_dev_X.iloc[idx]\n",
    "    result_new = result_new.append({'tweet_id':int(inf[0]), 'Q0': 'Q0', 'vclaim_id': int(inf[1]), 'rank': 1, 'score': inf[7], 'tag': 'COVID-19'},ignore_index=True)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>Q0</th>\n",
       "      <th>vclaim_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930955</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Q0</td>\n",
       "      <td>603</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003638</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>Q0</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847953</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Q0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906689</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Q0</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977914</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>Q0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003693</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>Q0</td>\n",
       "      <td>626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816548</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>Q0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873709</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51</td>\n",
       "      <td>Q0</td>\n",
       "      <td>453</td>\n",
       "      <td>1</td>\n",
       "      <td>0.850258</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62</td>\n",
       "      <td>Q0</td>\n",
       "      <td>518</td>\n",
       "      <td>1</td>\n",
       "      <td>1.024553</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_id  Q0 vclaim_id rank     score       tag\n",
       "0        0  Q0       507    1  0.930955  COVID-19\n",
       "1       12  Q0       603    1  1.003638  COVID-19\n",
       "2       23  Q0       460    1  0.847953  COVID-19\n",
       "3       30  Q0        71    1  0.906689  COVID-19\n",
       "4       33  Q0       207    1  0.977914  COVID-19\n",
       "5       36  Q0        25    1  1.003693  COVID-19\n",
       "6       39  Q0       626    1  0.816548  COVID-19\n",
       "7       49  Q0       105    1  0.873709  COVID-19\n",
       "8       51  Q0       453    1  0.850258  COVID-19\n",
       "9       62  Q0       518    1  1.024553  COVID-19"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new.to_csv('dev_set_results/golf_system_result_0.csv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFormat check: Passed\\n          metric @depth  score\\n             map      1  0.000\\n             map      3  0.000\\n             map      5  0.000\\n             map     10  0.000\\n             map     20  0.000\\n             map    all  0.000\\n       precision      1  0.000\\n       precision      3  0.000\\n       precision      5  0.000\\n       precision     10  0.000\\n       precision     20  0.000\\n       precision    all  0.000\\n reciprocal_rank      1  0.000\\n reciprocal_rank      3  0.000\\n reciprocal_rank      5  0.000\\n reciprocal_rank     10  0.000\\n reciprocal_rank     20  0.000\\n reciprocal_rank    all  0.000\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Format check: Passed\n",
    "          metric @depth  score\n",
    "             map      1  0.000\n",
    "             map      3  0.000\n",
    "             map      5  0.000\n",
    "             map     10  0.000\n",
    "             map     20  0.000\n",
    "             map    all  0.000\n",
    "       precision      1  0.000\n",
    "       precision      3  0.000\n",
    "       precision      5  0.000\n",
    "       precision     10  0.000\n",
    "       precision     20  0.000\n",
    "       precision    all  0.000\n",
    " reciprocal_rank      1  0.000\n",
    " reciprocal_rank      3  0.000\n",
    " reciprocal_rank      5  0.000\n",
    " reciprocal_rank     10  0.000\n",
    " reciprocal_rank     20  0.000\n",
    " reciprocal_rank    all  0.000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth=20, random_state=0, n_estimators=100).fit(X_tr, y_tr)\n",
    "# prob = clf.predict_proba(X_dev)[:, 1]\n",
    "# result_new = constructor(dev_tweet_vclaim, dev_X, prob)\n",
    "# score = scorer(dev_qrel, result_new)\n",
    "# print(\"2. Random Forest, MAP: \", score)\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=3).fit(X_tr, y_tr)\n",
    "# prob = neigh.predict_proba(X_dev)[:, 1]\n",
    "# result_new = constructor(dev_tweet_vclaim, dev_X, prob)\n",
    "# score = scorer(dev_qrel, result_new)\n",
    "# print(\"3. K neighbours, MAP: \", score)\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# clf = GradientBoostingClassifier(random_state=0).fit(X_tr, y_tr)\n",
    "# prob = clf.predict_proba(X_dev)[:, 1]\n",
    "# result_new = constructor(dev_tweet_vclaim, dev_X, prob)\n",
    "# score = scorer(dev_qrel, result_new)\n",
    "# print(\"4. Gradient Boosting, MAP: \", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
