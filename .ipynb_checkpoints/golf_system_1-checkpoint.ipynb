{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tr = pd.read_csv('data/train/tweets.queries.tsv', sep='\\t', header=0, index_col=0)\n",
    "tweets_tr.sort_index(inplace=True)\n",
    "\n",
    "tweets_dev = pd.read_csv('data/dev/tweets.queries.tsv', sep='\\t', header=0, index_col=0)\n",
    "tweets_dev.sort_index(inplace=True)\n",
    "\n",
    "tweets_te = pd.read_csv('data/test_tweets.queries.tsv', sep='\\t', header=0, index_col=0)\n",
    "tweets_te.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump needs to immediately divest from his bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A number of fraudulent text messages informing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fact check: The U.S. Army is NOT contacting an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The US drone attack on #Soleimani caught on ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1. To the dim witted reporters like @dmedin11:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Giants stars dare NFL to fine them for cleats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Fury over NFL's crackdown on player's 9/11 tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>During a recent interview with Australian jour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>#BreakingNews: We’re launching an exciting new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Phyllis Schlafly said “We’ll have a woman Pres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweet_content\n",
       "1    Trump needs to immediately divest from his bus...\n",
       "2    A number of fraudulent text messages informing...\n",
       "3    Fact check: The U.S. Army is NOT contacting an...\n",
       "4    The US drone attack on #Soleimani caught on ca...\n",
       "5    1. To the dim witted reporters like @dmedin11:...\n",
       "..                                                 ...\n",
       "994  Giants stars dare NFL to fine them for cleats ...\n",
       "995  Fury over NFL's crackdown on player's 9/11 tri...\n",
       "996  During a recent interview with Australian jour...\n",
       "997  #BreakingNews: We’re launching an exciting new...\n",
       "998  Phyllis Schlafly said “We’ll have a woman Pres...\n",
       "\n",
       "[800 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclaims = pd.read_csv('data/verified_claims.docs.tsv', sep='\\t', header=0, index_col=0)\n",
    "vclaims.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vclaim</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122 detainees released from confinement at Gua...</td>\n",
       "      <td>Did 122 Prisoners Released from Guantanamo by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70 per cent of the persons arrested during pro...</td>\n",
       "      <td>70% of Arrested Charlotte Protesters Are Out-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A \"Trump and Obama by the Numbers\" meme recoun...</td>\n",
       "      <td>Does This Meme Accurately Show ‘Trump and Obam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A \"large-scale killing\" of white farmers is ta...</td>\n",
       "      <td>Is a ‘Large-Scale Killing’ of White Farmers Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A \"law to separate families\" was enacted prior...</td>\n",
       "      <td>Was the ‘Law to Separate Families’ Passed in 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>“Slime,” a do-it-yourself gooey craft project ...</td>\n",
       "      <td>Does the “Slime” Craze Bring Serious Health Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>“Sun tea” (tea brewed by being left to steep i...</td>\n",
       "      <td>Bacteria in Sun Tea Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>“The Real Deal,” words of wisdom about gas, ge...</td>\n",
       "      <td>Red Thomas ‘Real Deal’ Letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>“Valentine’s Day” worm.</td>\n",
       "      <td>Valentine’s Day Worm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>“WTC Survivor.”</td>\n",
       "      <td>WTC Survivor Virus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vclaim  \\\n",
       "0      122 detainees released from confinement at Gua...   \n",
       "1      70 per cent of the persons arrested during pro...   \n",
       "2      A \"Trump and Obama by the Numbers\" meme recoun...   \n",
       "3      A \"large-scale killing\" of white farmers is ta...   \n",
       "4      A \"law to separate families\" was enacted prior...   \n",
       "...                                                  ...   \n",
       "10370  “Slime,” a do-it-yourself gooey craft project ...   \n",
       "10371  “Sun tea” (tea brewed by being left to steep i...   \n",
       "10372  “The Real Deal,” words of wisdom about gas, ge...   \n",
       "10373                            “Valentine’s Day” worm.   \n",
       "10374                                    “WTC Survivor.”   \n",
       "\n",
       "                                                   title  \n",
       "0      Did 122 Prisoners Released from Guantanamo by ...  \n",
       "1      70% of Arrested Charlotte Protesters Are Out-o...  \n",
       "2      Does This Meme Accurately Show ‘Trump and Obam...  \n",
       "3      Is a ‘Large-Scale Killing’ of White Farmers Un...  \n",
       "4      Was the ‘Law to Separate Families’ Passed in 1...  \n",
       "...                                                  ...  \n",
       "10370  Does the “Slime” Craze Bring Serious Health Ri...  \n",
       "10371                           Bacteria in Sun Tea Risk  \n",
       "10372                      Red Thomas ‘Real Deal’ Letter  \n",
       "10373                               Valentine’s Day Worm  \n",
       "10374                                 WTC Survivor Virus  \n",
       "\n",
       "[10375 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclaims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_tr = pd.read_csv('data/train/tweet-vclaim-pairs.qrels', sep='\\t', \n",
    "                       header=None, names=['tweet_id', '0', 'vclaim_id', 'relevance'])\n",
    "\n",
    "qrels_dev = pd.read_csv('data/dev/tweet-vclaim-pairs.qrels', sep='\\t', \n",
    "                       header=None, names=['tweet_id', '0', 'vclaim_id', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>0</th>\n",
       "      <th>vclaim_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>994</td>\n",
       "      <td>0</td>\n",
       "      <td>652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id  0  vclaim_id  relevance\n",
       "0           1  0        394          1\n",
       "1           2  0        670          1\n",
       "2           3  0        670          1\n",
       "3           4  0        141          1\n",
       "4           5  0         83          1\n",
       "..        ... ..        ...        ...\n",
       "796       994  0        652          1\n",
       "797       995  0        652          1\n",
       "798       996  0        778          1\n",
       "799       997  0        579          1\n",
       "800       998  0        539          1\n",
       "\n",
       "[801 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Raw Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "url_pattern = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "username_pattern = r\"@[^\\s]+\"\n",
    "hashtag_pattern = r\"\\B#\\w\\w+\"\n",
    "token_pattern = r\"\\b[A-Za-z][A-Za-z]+\\b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of preprocessing tweet\n",
    "def preprocess_tweet(tweet, \n",
    "                     url_pattern=url_pattern, username_pattern=username_pattern, \n",
    "                     hashtag_pattern=hashtag_pattern, token_pattern=token_pattern, \n",
    "                     remove_url=True, remove_username=True, remove_hashtag=True,\n",
    "                     stopwords=stopwords, with_stopwordsrm=True, with_stemming=True):\n",
    "    # remove content after '—'\n",
    "    tweet = tweet.split('—')[0]\n",
    "    \n",
    "    # remove url\n",
    "    if remove_url == True:\n",
    "        tweet = re.sub(url_pattern, \"\", tweet)\n",
    "        \n",
    "    # remove @username \n",
    "    if remove_username == True:\n",
    "        tweet = re.sub(username_pattern, \"\", tweet)\n",
    "        \n",
    "    # remove #hashtag\n",
    "    if remove_hashtag == True:\n",
    "        tweet = re.sub(hashtag_pattern, \"\", tweet)\n",
    "    \n",
    "    # lower case \n",
    "    tweet_lower = tweet.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, tweet_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    tweet_processed = \" \".join(words)\n",
    "    \n",
    "    return tweet_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict tweets_tr: tweet_id -> tweet_content\n",
    "tweets_tr_prep = {}\n",
    "for tweet_id in tweets_tr.index:\n",
    "    tweets_tr_prep[tweet_id] = preprocess_tweet(tweets_tr.loc[tweet_id, 'tweet_content'])\n",
    "\n",
    "# dict tweets_dev: tweet_id -> tweet_content\n",
    "tweets_dev_prep = {}\n",
    "for tweet_id in tweets_dev.index:\n",
    "    tweets_dev_prep[tweet_id] = preprocess_tweet(tweets_dev.loc[tweet_id, 'tweet_content'])\n",
    "    \n",
    "# dict tweets_te: tweet_id -> tweet_content\n",
    "tweets_te_prep = {}\n",
    "for tweet_id in tweets_te.index:\n",
    "    tweets_te_prep[tweet_id] = preprocess_tweet(tweets_te.loc[tweet_id, 'tweet_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of preprocessing vclaim\n",
    "def preprocess_text(text, token_pattern=token_pattern, stopwords=stopwords, \n",
    "                      with_stopwordsrm=True, with_stemming=True):\n",
    "    # lower case \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, text_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    text_processed = \" \".join(words)\n",
    "    \n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict vclaim_prep: vlciam_id -> [vlciam_content, vclaim_title]\n",
    "vclaims_prep = {}\n",
    "for vclaim_id in vclaims.index:\n",
    "    vclaims_prep[vclaim_id] = []\n",
    "    vclaims_prep[vclaim_id].append(preprocess_text(vclaims.loc[vclaim_id, 'vclaim']))\n",
    "    vclaims_prep[vclaim_id].append(preprocess_text(vclaims.loc[vclaim_id, 'title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Cosine Similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of computing consine similarity \n",
    "def compute_cs(tweets, vclaims):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vclaims_tfidf = vectorizer.fit_transform(vclaims)\n",
    "    \n",
    "    cosine_sims = {}\n",
    "    for (tweet_id, tweet_content) in tweets.items():\n",
    "        tweet_tfidf = vectorizer.transform([tweet_content])\n",
    "        cs = cosine_similarity(tweet_tfidf, vclaims_tfidf).flatten()\n",
    "        cosine_sims[tweet_id] = cs\n",
    "    \n",
    "    return cosine_sims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing Cosine Similarities for train and dev set\n",
    "vclaims_contents = [vclaim[0] for vclaim in vclaims_prep.values()]\n",
    "vclaims_titles = [vclaim[1] for vclaim in vclaims_prep.values()]\n",
    "\n",
    "cs_tvc_tr = compute_cs(tweets_tr_prep, vclaims_contents)\n",
    "cs_tvt_tr = compute_cs(tweets_tr_prep, vclaims_titles)\n",
    "\n",
    "cs_tvc_dev = compute_cs(tweets_dev_prep, vclaims_contents)\n",
    "cs_tvt_dev = compute_cs(tweets_dev_prep, vclaims_titles)\n",
    "\n",
    "cs_tvc_te = compute_cs(tweets_te_prep, vclaims_contents)\n",
    "cs_tvt_te = compute_cs(tweets_te_prep, vclaims_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs_tvc_tr = pd.DataFrame.from_dict(cs_tvc_tr, orient='index')\n",
    "df_cs_tvt_tr = pd.DataFrame.from_dict(cs_tvt_tr, orient='index')\n",
    "\n",
    "df_cs_tvc_dev = pd.DataFrame.from_dict(cs_tvc_dev, orient='index')\n",
    "df_cs_tvt_dev = pd.DataFrame.from_dict(cs_tvt_dev, orient='index')\n",
    "\n",
    "df_cs_tvc_te = pd.DataFrame.from_dict(cs_tvc_te, orient='index')\n",
    "df_cs_tvt_te = pd.DataFrame.from_dict(cs_tvt_te, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing BM25 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of computing BM25 score\n",
    "def compute_bm25(tokenized_tweets, tokenized_vclaims):\n",
    "    bm25kapi = BM25Okapi(tokenized_vclaims)\n",
    "    \n",
    "    bm25s = {}\n",
    "    for (tweet_id, tweet_content) in tokenized_tweets.items():\n",
    "        bm25s[tweet_id] = bm25kapi.get_scores(tweet_content)\n",
    "        \n",
    "    return bm25s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing pre-processed text\n",
    "tokenized_vclaims_contents = [vclaim[0].split(\" \") for vclaim in vclaims_prep.values()]\n",
    "tokenized_vclaims_titles = [vclaim[1].split(\" \") for vclaim in vclaims_prep.values()]\n",
    "\n",
    "tokenized_tweets_tr = {}\n",
    "for (tweet_id, tweet_content) in tweets_tr_prep.items():\n",
    "    tokenized_tweets_tr[tweet_id] = tweet_content.split(\" \")\n",
    "    \n",
    "tokenized_tweets_dev = {}\n",
    "for (tweet_id, tweet_content) in tweets_dev_prep.items():\n",
    "    tokenized_tweets_dev[tweet_id] = tweet_content.split(\" \")\n",
    "    \n",
    "tokenized_tweets_te = {}\n",
    "for (tweet_id, tweet_content) in tweets_te_prep.items():\n",
    "    tokenized_tweets_te[tweet_id] = tweet_content.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing BM25 Scores for train and test set\n",
    "bm25_tvc_tr = compute_bm25(tokenized_tweets_tr, tokenized_vclaims_contents)\n",
    "bm25_tvt_tr = compute_bm25(tokenized_tweets_tr, tokenized_vclaims_titles)\n",
    "\n",
    "bm25_tvc_dev = compute_bm25(tokenized_tweets_dev, tokenized_vclaims_contents)\n",
    "bm25_tvt_dev = compute_bm25(tokenized_tweets_dev, tokenized_vclaims_titles)\n",
    "\n",
    "bm25_tvc_te = compute_bm25(tokenized_tweets_te, tokenized_vclaims_contents)\n",
    "bm25_tvt_te = compute_bm25(tokenized_tweets_te, tokenized_vclaims_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bm25_tvc_tr = pd.DataFrame.from_dict(bm25_tvc_tr, orient='index')\n",
    "df_bm25_tvt_tr = pd.DataFrame.from_dict(bm25_tvt_tr, orient='index')\n",
    "\n",
    "df_bm25_tvc_dev = pd.DataFrame.from_dict(bm25_tvc_dev, orient='index')\n",
    "df_bm25_tvt_dev = pd.DataFrame.from_dict(bm25_tvt_dev, orient='index')\n",
    "\n",
    "df_bm25_tvc_te = pd.DataFrame.from_dict(bm25_tvc_te, orient='index')\n",
    "df_bm25_tvt_te = pd.DataFrame.from_dict(bm25_tvt_te, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing dataset with 4 features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_tids = []\n",
    "for tweet_id in tweets_tr_prep.keys():\n",
    "    data_tr_tids.extend((np.ones(vclaims.shape[0]) * tweet_id).tolist())\n",
    "    \n",
    "data_tr_vids = []\n",
    "for i in range(tweets_tr.shape[0]):\n",
    "    data_tr_vids.extend(list(vclaims_prep.keys()))\n",
    "    \n",
    "data_tr_labels = []\n",
    "for tweet_id in tweets_tr_prep.keys():\n",
    "    labels = np.zeros(vclaims.shape[0])\n",
    "    if tweet_id in qrels_tr['tweet_id'].values:\n",
    "        for index in qrels_tr[qrels_tr['tweet_id'] == tweet_id]['vclaim_id'].values:\n",
    "            labels[index] = 1\n",
    "    data_tr_labels.extend(labels)\n",
    "    \n",
    "data_tr = pd.DataFrame(columns=['tid', 'vid', 'cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt', 'label'])\n",
    "data_tr['tid'] = data_tr_tids\n",
    "data_tr['vid'] = data_tr_vids\n",
    "data_tr['cs_tvc'] = df_cs_tvc_tr.values.flatten()\n",
    "data_tr['cs_tvt'] = df_cs_tvt_tr.values.flatten()\n",
    "data_tr['bm25_tvc'] = df_bm25_tvc_tr.values.flatten()\n",
    "data_tr['bm25_tvt'] = df_bm25_tvt_tr.values.flatten()\n",
    "data_tr['label'] = data_tr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev_tids = []\n",
    "for tweet_id in tweets_dev_prep.keys():\n",
    "    data_dev_tids.extend((np.ones(vclaims.shape[0]) * tweet_id).tolist())\n",
    "    \n",
    "data_dev_vids = []\n",
    "for i in range(tweets_dev.shape[0]):\n",
    "    data_dev_vids.extend(list(vclaims_prep.keys()))\n",
    "    \n",
    "data_dev_labels = []\n",
    "for tweet_id in tweets_dev_prep.keys():\n",
    "    labels = np.zeros(vclaims.shape[0])\n",
    "    if tweet_id in qrels_dev['tweet_id'].values:\n",
    "        for index in qrels_dev[qrels_dev['tweet_id'] == tweet_id]['vclaim_id'].values:\n",
    "            labels[index] = 1\n",
    "    data_dev_labels.extend(labels)\n",
    "    \n",
    "data_dev = pd.DataFrame(columns=['tid', 'vid', 'cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt', 'label'])\n",
    "data_dev['tid'] = data_dev_tids\n",
    "data_dev['vid'] = data_dev_vids\n",
    "data_dev['cs_tvc'] = df_cs_tvc_dev.values.flatten()\n",
    "data_dev['cs_tvt'] = df_cs_tvt_dev.values.flatten()\n",
    "data_dev['bm25_tvc'] = df_bm25_tvc_dev.values.flatten()\n",
    "data_dev['bm25_tvt'] = df_bm25_tvt_dev.values.flatten()\n",
    "data_dev['label'] = data_dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_te_tids = []\n",
    "for tweet_id in tweets_te_prep.keys():\n",
    "    data_te_tids.extend((np.ones(vclaims.shape[0]) * tweet_id).tolist())\n",
    "    \n",
    "data_te_vids = []\n",
    "for i in range(tweets_te.shape[0]):\n",
    "    data_te_vids.extend(list(vclaims_prep.keys()))\n",
    "    \n",
    "data_te = pd.DataFrame(columns=['tid', 'vid', 'cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt', 'label'])\n",
    "data_te['tid'] = data_te_tids\n",
    "data_te['vid'] = data_te_vids\n",
    "data_te['cs_tvc'] = df_cs_tvc_te.values.flatten()\n",
    "data_te['cs_tvt'] = df_cs_tvt_te.values.flatten()\n",
    "data_te['bm25_tvc'] = df_bm25_tvc_te.values.flatten()\n",
    "data_te['bm25_tvt'] = df_bm25_tvt_te.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = data_tr[['cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt']].values, data_tr['label'].values\n",
    "X_dev, y_dev = data_dev[['cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt']].values, data_dev['label'].values\n",
    "X_te = data_te[['cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing class weights to handle data imbalance\n",
    "class_weight = {}\n",
    "for label in set(y_dev):\n",
    "    class_weight[label] = np.sum(y_dev == label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/administrator/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C=0.1, random_state=0, class_weight=class_weight, max_iter=1000).fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generating result for dev data set\n",
    "score_dev = np.sum(X_dev * clf.coef_, axis=1) + clf.intercept_\n",
    "\n",
    "result_dev_score = pd.DataFrame(columns=['tid','vid', 'score'])\n",
    "result_dev_score['tid'] = data_dev['tid']\n",
    "result_dev_score['vid'] = data_dev['vid']\n",
    "result_dev_score['score'] = score_dev\n",
    "\n",
    "result_dev = pd.DataFrame(columns=['tweet_id', 'Q0', 'vclaim_id', 'rank', 'score', 'tag'])\n",
    "\n",
    "tid = list(result_dev_score.groupby(by='tid').groups.keys())\n",
    "for i in tid:\n",
    "    idx = result_dev_score[result_dev_score['tid'] == i]['score'].idxmax()\n",
    "    inf = result_dev_score.iloc[idx]\n",
    "    result_dev = result_dev.append({'tweet_id':int(inf[0]), 'Q0':'Q0', 'vclaim_id':int(inf[1]), \n",
    "                                    'rank':1, 'score':inf[2], 'tag': 'COVID-19'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>Q0</th>\n",
       "      <th>vclaim_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>2194</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.949281</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Q0</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.897546</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>Q0</td>\n",
       "      <td>4318</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.955595</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Q0</td>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.941585</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>Q0</td>\n",
       "      <td>1275</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.965971</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>960</td>\n",
       "      <td>Q0</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.845738</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>966</td>\n",
       "      <td>Q0</td>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.809903</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>968</td>\n",
       "      <td>Q0</td>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.877747</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>982</td>\n",
       "      <td>Q0</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.957366</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>986</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.945329</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id  Q0 vclaim_id rank     score       tag\n",
       "0          0  Q0      2194    1 -0.949281  COVID-19\n",
       "1         11  Q0       639    1 -0.897546  COVID-19\n",
       "2         21  Q0      4318    1 -0.955595  COVID-19\n",
       "3         28  Q0       219    1 -0.941585  COVID-19\n",
       "4         31  Q0      1275    1 -0.965971  COVID-19\n",
       "..       ...  ..       ...  ...       ...       ...\n",
       "192      960  Q0       178    1 -0.845738  COVID-19\n",
       "193      966  Q0       355    1 -0.809903  COVID-19\n",
       "194      968  Q0       524    1 -0.877747  COVID-19\n",
       "195      982  Q0       249    1 -0.957366  COVID-19\n",
       "196      986  Q0        30    1 -0.945329  COVID-19\n",
       "\n",
       "[197 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dev.to_csv('dev_set_results/golf_system_result_dev_1.csv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating result for test data set\n",
    "score_te = np.sum(X_te * clf.coef_, axis=1) + clf.intercept_\n",
    "\n",
    "result_te_score = pd.DataFrame(columns=['tid','vid', 'score'])\n",
    "result_te_score['tid'] = data_te['tid']\n",
    "result_te_score['vid'] = data_te['vid']\n",
    "result_te_score['score'] = score_te\n",
    "\n",
    "result_te = pd.DataFrame(columns=['tweet_id', 'Q0', 'vclaim_id', 'rank', 'score', 'tag'])\n",
    "\n",
    "tid = list(result_te_score.groupby(by='tid').groups.keys())\n",
    "for i in tid:\n",
    "    idx = result_te_score[result_te_score['tid'] == i]['score'].idxmax()\n",
    "    inf = result_te_score.iloc[idx]\n",
    "    result_te = result_te.append({'tweet_id':int(inf[0]), 'Q0':'Q0', 'vclaim_id':int(inf[1]), \n",
    "                                    'rank':1, 'score':inf[2], 'tag': 'COVID-19'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>Q0</th>\n",
       "      <th>vclaim_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>Q0</td>\n",
       "      <td>6094</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.884481</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>Q0</td>\n",
       "      <td>6094</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.908192</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.915467</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002</td>\n",
       "      <td>Q0</td>\n",
       "      <td>8005</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.911853</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>Q0</td>\n",
       "      <td>8005</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.914699</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1194</td>\n",
       "      <td>Q0</td>\n",
       "      <td>9974</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.978785</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1195</td>\n",
       "      <td>Q0</td>\n",
       "      <td>6672</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.980529</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1196</td>\n",
       "      <td>Q0</td>\n",
       "      <td>8855</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.967455</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1197</td>\n",
       "      <td>Q0</td>\n",
       "      <td>5553</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.897356</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1198</td>\n",
       "      <td>Q0</td>\n",
       "      <td>9807</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.944666</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id  Q0 vclaim_id rank     score       tag\n",
       "0        999  Q0      6094    1 -0.884481  COVID-19\n",
       "1       1000  Q0      6094    1 -0.908192  COVID-19\n",
       "2       1001  Q0       582    1 -0.915467  COVID-19\n",
       "3       1002  Q0      8005    1 -0.911853  COVID-19\n",
       "4       1003  Q0      8005    1 -0.914699  COVID-19\n",
       "..       ...  ..       ...  ...       ...       ...\n",
       "195     1194  Q0      9974    1 -0.978785  COVID-19\n",
       "196     1195  Q0      6672    1 -0.980529  COVID-19\n",
       "197     1196  Q0      8855    1 -0.967455  COVID-19\n",
       "198     1197  Q0      5553    1 -0.897356  COVID-19\n",
       "199     1198  Q0      9807    1 -0.944666  COVID-19\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_te.to_csv('test_set_results/golf_system_result_te_1.csv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 evaluate.py -s golf_system_result_dev_1.csv -g data/dev/tweet-vclaim-pairs.qrels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
